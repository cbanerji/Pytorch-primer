{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised learning using a feedforward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #Features = 2\n",
      "\n",
      " #Samples = 63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of claims</th>\n",
       "      <th>Payment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>392.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>422.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of claims  Payment \n",
       "0               108     392.5\n",
       "1                19      46.2\n",
       "2                13      15.7\n",
       "3               124     422.2\n",
       "4                40     119.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and preprocess the data according to our requirement\n",
    "import pandas as pd\n",
    "data = pd.read_csv('insurance.csv')\n",
    "print('\\n #Features = '+str(data.shape[1]))\n",
    "print('\\n #Samples = '+str(data.shape[0]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following is the code for the training network.\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "torch.manual_seed(47)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "dat = data.to_numpy(dtype= np.float32) # dataframe  to numpy \n",
    "# Split data into input and labels\n",
    "x = torch.from_numpy(dat[:,[0]])\n",
    "x = torch.nn.functional.normalize(x, p=2.0, dim = 0)\n",
    "y = torch.from_numpy(dat[:,[1]])\n",
    "\n",
    "# Split data into test and train\n",
    "train_size = int(0.8*len(dat))\n",
    "test_size = len(dat)- train_size\n",
    "x_train, x_test = torch.utils.data.random_split(x, [train_size, test_size])\n",
    "y_train, y_test = torch.utils.data.random_split(y, [train_size, test_size])\n",
    "\n",
    "# define train and test Datasets\n",
    "class CustomDataset_train(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.num_samples = len(x_train)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_train[index], self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "class CustomDataset_test(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.num_samples = len(x_test)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_test[index], self.y_test[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "data_train = CustomDataset_train()\n",
    "data_test = CustomDataset_test()\n",
    "\n",
    "batch_size= 5 #set batch size\n",
    "\n",
    "train_dataloader = DataLoader(dataset = data_train, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset = data_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myModel(\n",
      "  (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "input_size = x.shape[1]\n",
    "output_size = y.shape[1]\n",
    "\n",
    "# define network architecture\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim, hidden_size1 =128, hidden_size2 = 128):\n",
    "        super(myModel, self).__init__()\n",
    "        #define network layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "      \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "model = myModel(input_size, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function, optimizer and hyperparameters\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "total_step = len(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Train_loss: 13885.284180  [    5/   50]\n",
      "Train_loss: 50193.808594  [   10/   50]\n",
      "Train_loss: 1267.078369  [   15/   50]\n",
      "Train_loss: 2156.162109  [   20/   50]\n",
      "Train_loss: 14770.377930  [   25/   50]\n",
      "Train_loss: 14362.869141  [   30/   50]\n",
      "Train_loss: 13700.504883  [   35/   50]\n",
      "Train_loss: 6330.865723  [   40/   50]\n",
      "Train_loss: 17924.349609  [   45/   50]\n",
      "Train_loss: 6530.818848  [   50/   50]\n",
      "Avg_Test_loss: 19056.734701 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Train_loss: 38804.339844  [    5/   50]\n",
      "Train_loss: 6585.289062  [   10/   50]\n",
      "Train_loss: 8667.189453  [   15/   50]\n",
      "Train_loss: 8287.187500  [   20/   50]\n",
      "Train_loss: 10626.510742  [   25/   50]\n",
      "Train_loss: 1715.315430  [   30/   50]\n",
      "Train_loss: 5992.055664  [   35/   50]\n",
      "Train_loss: 9693.899414  [   40/   50]\n",
      "Train_loss: 1436.408691  [   45/   50]\n",
      "Train_loss: 7567.862305  [   50/   50]\n",
      "Avg_Test_loss: 11981.234843 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Train_loss: 3096.894531  [    5/   50]\n",
      "Train_loss: 10226.685547  [   10/   50]\n",
      "Train_loss: 1851.048218  [   15/   50]\n",
      "Train_loss: 4267.943359  [   20/   50]\n",
      "Train_loss: 7362.700195  [   25/   50]\n",
      "Train_loss: 3910.000732  [   30/   50]\n",
      "Train_loss: 24497.417969  [   35/   50]\n",
      "Train_loss: 3078.147705  [   40/   50]\n",
      "Train_loss: 5346.802246  [   45/   50]\n",
      "Train_loss: 5579.154785  [   50/   50]\n",
      "Avg_Test_loss: 11756.610596 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Train_loss: 5132.149414  [    5/   50]\n",
      "Train_loss: 4374.024414  [   10/   50]\n",
      "Train_loss: 4512.077148  [   15/   50]\n",
      "Train_loss: 24241.441406  [   20/   50]\n",
      "Train_loss: 9045.220703  [   25/   50]\n",
      "Train_loss: 4500.245117  [   30/   50]\n",
      "Train_loss: 4589.591309  [   35/   50]\n",
      "Train_loss: 4921.942383  [   40/   50]\n",
      "Train_loss: 4337.265625  [   45/   50]\n",
      "Train_loss: 2901.478027  [   50/   50]\n",
      "Avg_Test_loss: 9678.107992 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Train_loss: 3538.182861  [    5/   50]\n",
      "Train_loss: 2331.884521  [   10/   50]\n",
      "Train_loss: 3387.044922  [   15/   50]\n",
      "Train_loss: 1650.487915  [   20/   50]\n",
      "Train_loss: 4769.115234  [   25/   50]\n",
      "Train_loss: 4275.779785  [   30/   50]\n",
      "Train_loss: 28637.925781  [   35/   50]\n",
      "Train_loss: 3216.870605  [   40/   50]\n",
      "Train_loss: 7536.552246  [   45/   50]\n",
      "Train_loss: 11924.349609  [   50/   50]\n",
      "Avg_Test_loss: 15310.242676 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Train_loss: 925.709167  [    5/   50]\n",
      "Train_loss: 3290.514160  [   10/   50]\n",
      "Train_loss: 3313.316406  [   15/   50]\n",
      "Train_loss: 2590.818359  [   20/   50]\n",
      "Train_loss: 2814.645020  [   25/   50]\n",
      "Train_loss: 7895.640625  [   30/   50]\n",
      "Train_loss: 7800.898438  [   35/   50]\n",
      "Train_loss: 6225.552246  [   40/   50]\n",
      "Train_loss: 23676.212891  [   45/   50]\n",
      "Train_loss: 8355.193359  [   50/   50]\n",
      "Avg_Test_loss: 13248.815755 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Train_loss: 7808.750000  [    5/   50]\n",
      "Train_loss: 4010.198486  [   10/   50]\n",
      "Train_loss: 2562.806396  [   15/   50]\n",
      "Train_loss: 3662.652832  [   20/   50]\n",
      "Train_loss: 5470.335938  [   25/   50]\n",
      "Train_loss: 10898.400391  [   30/   50]\n",
      "Train_loss: 2742.431152  [   35/   50]\n",
      "Train_loss: 22039.023438  [   40/   50]\n",
      "Train_loss: 4474.907227  [   45/   50]\n",
      "Train_loss: 3655.368408  [   50/   50]\n",
      "Avg_Test_loss: 8908.759847 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Train_loss: 7840.767090  [    5/   50]\n",
      "Train_loss: 24266.019531  [   10/   50]\n",
      "Train_loss: 3139.260254  [   15/   50]\n",
      "Train_loss: 1064.529541  [   20/   50]\n",
      "Train_loss: 2916.000244  [   25/   50]\n",
      "Train_loss: 3287.313965  [   30/   50]\n",
      "Train_loss: 7565.602539  [   35/   50]\n",
      "Train_loss: 8218.234375  [   40/   50]\n",
      "Train_loss: 3084.281982  [   45/   50]\n",
      "Train_loss: 4641.602539  [   50/   50]\n",
      "Avg_Test_loss: 9670.166504 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Train_loss: 4403.874023  [    5/   50]\n",
      "Train_loss: 3156.740723  [   10/   50]\n",
      "Train_loss: 3239.758057  [   15/   50]\n",
      "Train_loss: 5368.183594  [   20/   50]\n",
      "Train_loss: 3137.604492  [   25/   50]\n",
      "Train_loss: 4567.457520  [   30/   50]\n",
      "Train_loss: 1256.017334  [   35/   50]\n",
      "Train_loss: 17009.408203  [   40/   50]\n",
      "Train_loss: 24650.289062  [   45/   50]\n",
      "Train_loss: 2056.798828  [   50/   50]\n",
      "Avg_Test_loss: 9986.640828 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Train_loss: 4576.699219  [    5/   50]\n",
      "Train_loss: 1514.785400  [   10/   50]\n",
      "Train_loss: 3825.032715  [   15/   50]\n",
      "Train_loss: 3202.519287  [   20/   50]\n",
      "Train_loss: 7399.657715  [   25/   50]\n",
      "Train_loss: 4985.512695  [   30/   50]\n",
      "Train_loss: 846.213013  [   35/   50]\n",
      "Train_loss: 7346.034180  [   40/   50]\n",
      "Train_loss: 8257.696289  [   45/   50]\n",
      "Train_loss: 23847.542969  [   50/   50]\n",
      "Avg_Test_loss: 9373.522705 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, batch_size):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * batch_size\n",
    "            print(f\"Train_loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg_Test_loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "epochs = 10\n",
    "loss_train = []\n",
    "loss_test = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer, batch_size)\n",
    "    test(test_dataloader, model, loss_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
