{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised learning using a feedforward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial view of \n",
      ": x: tensor([[-3.1416],\n",
      "        [-3.1100],\n",
      "        [-3.0784],\n",
      "        [-3.0469],\n",
      "        [-3.0153],\n",
      "        [-2.9837],\n",
      "        [-2.9521],\n",
      "        [-2.9206],\n",
      "        [-2.8890],\n",
      "        [-2.8574]]), \n",
      " y: tensor([[-1.0000],\n",
      "        [-0.9995],\n",
      "        [-0.9980],\n",
      "        [-0.9955],\n",
      "        [-0.9920],\n",
      "        [-0.9876],\n",
      "        [-0.9821],\n",
      "        [-0.9757],\n",
      "        [-0.9683],\n",
      "        [-0.9599]])\n"
     ]
    }
   ],
   "source": [
    "# Get and preprocess the data according to our requirement\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Generate toy data\n",
    "x = np.linspace(-np.pi, np.pi, 200).reshape(-1,1)\n",
    "x = x.astype('float32')\n",
    "y = np.cos(x).reshape(-1,1)\n",
    "y = y.astype('float32')\n",
    "x = torch.from_numpy(x)\n",
    "y = torch.from_numpy(y)\n",
    "print('Partial view of \\n: x: %s, \\n y: %s' %(x[0:10,:],y[0:10,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "torch.manual_seed(78)# Set manual seed \n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training data in train and test\n",
    "train_size = int(0.8*len(x))\n",
    "test_size = len(x)- train_size\n",
    "x_train, x_test = torch.utils.data.random_split(x, [train_size, test_size])\n",
    "y_train, y_test = torch.utils.data.random_split(y, [train_size, test_size])\n",
    "\n",
    "# Following is the code for the training network.\n",
    "class CustomDataset_train(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.num_samples = len(x_train)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_train[index], self.y_train[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "class CustomDataset_test(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.num_samples = len(x_test)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_test[index], self.y_test[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "data_train = CustomDataset_train()\n",
    "data_test = CustomDataset_test()\n",
    "trainloader = DataLoader(dataset = data_train, batch_size=batch_size, shuffle=True)\n",
    "testloader = DataLoader(dataset = data_test, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myModel(\n",
      "  (fc1): Linear(in_features=1, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "input_size = x.shape[1]\n",
    "output_size = y.shape[1]\n",
    "\n",
    "# define network architecture\n",
    "class myModel(nn.Module):\n",
    "    def __init__(self,input_dim, output_dim, hidden_size =128):\n",
    "        super(myModel, self).__init__()\n",
    "        #define network layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "      \n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "    \n",
    "model = myModel(input_size, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define loss function, optimizer and hyperparameters\n",
    "loss = torch.nn.MSELoss()\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "num_epochs =100\n",
    "total_step = len(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, overall Loss: 8.277281820774078\n",
      "Epoch: 2, overall Loss: 7.656789243221283\n",
      "Epoch: 3, overall Loss: 7.196322649717331\n",
      "Epoch: 4, overall Loss: 6.7521155178546906\n",
      "Epoch: 5, overall Loss: 6.434007972478867\n",
      "Epoch: 6, overall Loss: 6.142618626356125\n",
      "Epoch: 7, overall Loss: 5.934903025627136\n",
      "Epoch: 8, overall Loss: 5.767867177724838\n",
      "Epoch: 9, overall Loss: 5.627138555049896\n",
      "Epoch: 10, overall Loss: 5.524194777011871\n",
      "Epoch: 11, overall Loss: 5.453497499227524\n",
      "Epoch: 12, overall Loss: 5.397998034954071\n",
      "Epoch: 13, overall Loss: 5.348764628171921\n",
      "Epoch: 14, overall Loss: 5.31639438867569\n",
      "Epoch: 15, overall Loss: 5.289619892835617\n",
      "Epoch: 16, overall Loss: 5.275210291147232\n",
      "Epoch: 17, overall Loss: 5.270663768053055\n",
      "Epoch: 18, overall Loss: 5.252311170101166\n",
      "Epoch: 19, overall Loss: 5.248828828334808\n",
      "Epoch: 20, overall Loss: 5.241208493709564\n",
      "Epoch: 21, overall Loss: 5.237889438867569\n",
      "Epoch: 22, overall Loss: 5.236937522888184\n",
      "Epoch: 23, overall Loss: 5.234429270029068\n",
      "Epoch: 24, overall Loss: 5.231446266174316\n",
      "Epoch: 25, overall Loss: 5.231088489294052\n",
      "Epoch: 26, overall Loss: 5.230896085500717\n",
      "Epoch: 27, overall Loss: 5.2267454862594604\n",
      "Epoch: 28, overall Loss: 5.22749862074852\n",
      "Epoch: 29, overall Loss: 5.230928897857666\n",
      "Epoch: 30, overall Loss: 5.224863737821579\n",
      "Epoch: 31, overall Loss: 5.230248123407364\n",
      "Epoch: 32, overall Loss: 5.225159198045731\n",
      "Epoch: 33, overall Loss: 5.223569869995117\n",
      "Epoch: 34, overall Loss: 5.231805145740509\n",
      "Epoch: 35, overall Loss: 5.227798968553543\n",
      "Epoch: 36, overall Loss: 5.220864176750183\n",
      "Epoch: 37, overall Loss: 5.220003068447113\n",
      "Epoch: 38, overall Loss: 5.2204949259758\n",
      "Epoch: 39, overall Loss: 5.2252317070961\n",
      "Epoch: 40, overall Loss: 5.217774897813797\n",
      "Epoch: 41, overall Loss: 5.224354118108749\n",
      "Epoch: 42, overall Loss: 5.215825438499451\n",
      "Epoch: 43, overall Loss: 5.216921120882034\n",
      "Epoch: 44, overall Loss: 5.220150142908096\n",
      "Epoch: 45, overall Loss: 5.21793058514595\n",
      "Epoch: 46, overall Loss: 5.215578496456146\n",
      "Epoch: 47, overall Loss: 5.213128358125687\n",
      "Epoch: 48, overall Loss: 5.215266048908234\n",
      "Epoch: 49, overall Loss: 5.216008961200714\n",
      "Epoch: 50, overall Loss: 5.21132493019104\n",
      "Epoch: 51, overall Loss: 5.210827082395554\n",
      "Epoch: 52, overall Loss: 5.209201514720917\n",
      "Epoch: 53, overall Loss: 5.213277220726013\n",
      "Epoch: 54, overall Loss: 5.209102928638458\n",
      "Epoch: 55, overall Loss: 5.213285505771637\n",
      "Epoch: 56, overall Loss: 5.208847880363464\n",
      "Epoch: 57, overall Loss: 5.208557277917862\n",
      "Epoch: 58, overall Loss: 5.206931620836258\n",
      "Epoch: 59, overall Loss: 5.205179393291473\n",
      "Epoch: 60, overall Loss: 5.205154746770859\n",
      "Epoch: 61, overall Loss: 5.205575883388519\n",
      "Epoch: 62, overall Loss: 5.2010199427604675\n",
      "Epoch: 63, overall Loss: 5.201466351747513\n",
      "Epoch: 64, overall Loss: 5.201564699411392\n",
      "Epoch: 65, overall Loss: 5.200246423482895\n",
      "Epoch: 66, overall Loss: 5.200713127851486\n",
      "Epoch: 67, overall Loss: 5.20335590839386\n",
      "Epoch: 68, overall Loss: 5.197533547878265\n",
      "Epoch: 69, overall Loss: 5.199537694454193\n",
      "Epoch: 70, overall Loss: 5.200078308582306\n",
      "Epoch: 71, overall Loss: 5.199306011199951\n",
      "Epoch: 72, overall Loss: 5.196580797433853\n",
      "Epoch: 73, overall Loss: 5.1980259120464325\n",
      "Epoch: 74, overall Loss: 5.1978790163993835\n",
      "Epoch: 75, overall Loss: 5.1960607171058655\n",
      "Epoch: 76, overall Loss: 5.192818611860275\n",
      "Epoch: 77, overall Loss: 5.194092154502869\n",
      "Epoch: 78, overall Loss: 5.194336473941803\n",
      "Epoch: 79, overall Loss: 5.197355657815933\n",
      "Epoch: 80, overall Loss: 5.191992431879044\n",
      "Epoch: 81, overall Loss: 5.192875027656555\n",
      "Epoch: 82, overall Loss: 5.195154547691345\n",
      "Epoch: 83, overall Loss: 5.18990883231163\n",
      "Epoch: 84, overall Loss: 5.1891525983810425\n",
      "Epoch: 85, overall Loss: 5.189405411481857\n",
      "Epoch: 86, overall Loss: 5.188197165727615\n",
      "Epoch: 87, overall Loss: 5.187389105558395\n",
      "Epoch: 88, overall Loss: 5.18840029835701\n",
      "Epoch: 89, overall Loss: 5.1855482161045074\n",
      "Epoch: 90, overall Loss: 5.186588883399963\n",
      "Epoch: 91, overall Loss: 5.184578239917755\n",
      "Epoch: 92, overall Loss: 5.187565237283707\n",
      "Epoch: 93, overall Loss: 5.186336576938629\n",
      "Epoch: 94, overall Loss: 5.183679014444351\n",
      "Epoch: 95, overall Loss: 5.189189314842224\n",
      "Epoch: 96, overall Loss: 5.181376934051514\n",
      "Epoch: 97, overall Loss: 5.183247745037079\n",
      "Epoch: 98, overall Loss: 5.184228807687759\n",
      "Epoch: 99, overall Loss: 5.186034590005875\n",
      "Epoch: 100, overall Loss: 5.179982393980026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7f580d6d68>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "los_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    overall_loss = 0\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model(inputs)\n",
    "        l = loss(y_pred, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        overall_loss += l.item()\n",
    "        \n",
    "    print('Epoch: %s, overall Loss: %s'%(epoch+1,overall_loss))\n",
    "    los_list.append(overall_loss)\n",
    "    \n",
    "\n",
    "ep = np.arange(len(los_list))\n",
    "plt.plot(ep,los_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44773635268211365\n",
      "0.9077961146831512\n",
      "1.2972548305988312\n"
     ]
    }
   ],
   "source": [
    "loss_test = []\n",
    "with torch.no_grad():\n",
    "    overall_test_loss = 0\n",
    "    for inputs, labels in testloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = model(inputs)\n",
    "        lo = loss(pred, labels)\n",
    "        overall_test_loss += lo.item()\n",
    "        print(overall_test_loss)\n",
    "    loss_test.append(overall_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
